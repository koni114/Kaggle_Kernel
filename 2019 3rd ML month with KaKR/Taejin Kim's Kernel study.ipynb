{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 태진님의 커널 필사 공부!\n",
    "# 2019-07-05 \n",
    "# Generator, keras Generator\n",
    "\n",
    "# 이론 정리\n",
    "# 개와 고양이를 분류하는 것과 달리, 차 종 분류는 일반적인 이미지 분류보다 어려움이 존재\n",
    "# 분류 문제에서 가장 먼저 확인 -> target variables 의 distribution 확인\n",
    "# Bounding Box : 이미지 내부에서 특정 object를 박스로 레이블한 것을 말함. 보통 좌측 상단, 우측 하단 좌표가 주어짐.\n",
    "# -> 이러한 좌표를 찾는 모델도 있음! \n",
    "# -> 쓰는 이유, 어떤 이미지에는 내가 원하는 Target Object 뿐만 아니라, Noise가 섞여 있을 수 있음\n",
    "#    그래서 Bounding Box 수행!\n",
    "# -> 원래는 Bounding Box를 구하는 모델링을 수행해야 한다!\n",
    "\n",
    "\n",
    "# trainSet / TestSet\n",
    "# trainSet을 다시 vaildationSet 으로 나눔\n",
    "# 보통 CV, LB라는 용어가 나오는데, CV : crossValidation 을 통한 검증 accuracy, LB : 리더보드에 올라간 Public Score를 의미\n",
    "\n",
    "# ** 제너레이터(Generator)\n",
    "# 배치사이즈 단위 만큼 파일을 불러와 학습하고 끝나면 다시 불러와서 학습하는 방법을 반복하는 것을 의미\n",
    "# 전체 학습으 하더라도 메모리를 적게 사용! -> 핵심\n",
    "# 코랩이나 캐글 커널 같은 클라우드 환경 OR 로컬 환경에서 정말 유용하게 사용할 수 있음\n",
    "# 이미지 프로세싱에서 없어서는 안 될 필수 과정\n",
    " \n",
    "# ** 케라스 제너레이터    \n",
    "# ImageDataGenerator 는 제너레이터 기능은 물론, 제너레이터를 정의하면서, 동시에 Data에 원하는 Noise까지 부여\n",
    "# 주어진 데이터가 이미지가 아닌 경우 직접 제너레이터를 설계해야 하는 경우도 존재.\n",
    "\n",
    "# ** ResNet \n",
    "# 유명하다.\n",
    "# Residual를 이용한 획기적인 모델로 평가됨\n",
    "# Pretrained Model을 불러오기 위해서는 커널의 Internet 옵션이 활성화 되어 있어야 함\n",
    "\n",
    "# **Pretrained(선행 학습, 사전 훈련, 전처리과정이라고 함) Model\n",
    "# Milti Layered Perceptron 에서 Weight와 Bias를 잘 초기화 시키는 방법이다.\n",
    "# 사용시 한가지 주의할 점. Pretrained Model은 경우에 따라 다양하게 사용될 수 있기 때문에, Model output 부분을 잘라버린 채 로드되는 경우가 있음.(include_top = False)\n",
    "# 이럴 때는 직접 output을 만들어주어야 함\n",
    "\n",
    "# macro 평균 vs micro 평균\n",
    "#        A반    B반    C반\n",
    "#  학생수  9     10     8\n",
    "#  평균   40     70    90\n",
    "\n",
    "# 평균의 합을 반의 개수로 나누는 방법 -> macro 평균\n",
    "# 전체의 값들의 평균 개념 -> Micro 평균\n",
    "\n",
    "# library load\n",
    "import gc             # garbage collection library\n",
    "import os             # 기본적인 환경을 setting 할 수 있는 library(ex) dir 등) \n",
    "import warnings       # warnings을 무시하기 위해 일반적으로 사용되는 library\n",
    "import numpy as np    # numpy package : array, 배열 연산, slicing 에 자주 사용되는 library\n",
    "import pandas as pd   # 주로 분석 모델에 사용하는 package\n",
    "import seaborn as sns # matplotlib를 support 해주는 library\n",
    "import matplotlib.pyplot as plt \n",
    "from tqdm import tqdm # 진행바를 만들어주는 library\n",
    "\n",
    "from keras import backend as K # 딥러닝 모델 변수들의 초기값을 setting해 주기 위한 library\n",
    "warnings.filterwarnings(action = 'ignore')\n",
    "K.image_data_format() # channel_first 인 경우, (샘플 수, 랭크(축) 수, 행, 열)  4D tensor 필터 수 ->  축 수\n",
    "                      # channel_last  인 경우, (샘플 수, 행, 열, 필터 수)      4D tensor  -> default\n",
    "\n",
    "DATA_PATH = '../input/'  # 기본 디렉토리 설정하기 위한 변수 선언\n",
    "os.listdir(DATA_PATH)    # 기본 디렉토리 설정 -> 해당 디렉토리의 file 이나 folder 확인 가능\n",
    "\n",
    "# 이미지 폴더 경로\n",
    "TRAIN_IMG_PATH = os.path.join(DATA_PATH, 'train')\n",
    "TEST_IMG_PATH = os.path.join(DATA_PATH, 'test')\n",
    "\n",
    "# CSV 파일 경로를 통해 data read : train, test, class\n",
    "df_train = pd.read_csv(os.path.join(DATA_PATH, 'train.csv'))\n",
    "df_test = pd.read_csv(os.path.join(DATA_PATH, 'test.csv'))\n",
    "df_class = pd.read_csv(os.path.join(DATA_PATH, 'class.csv'))\n",
    "\n",
    "df_train.head() # 몇개만 데이터 확인해보기 위해, head() 사용\n",
    "df_test.head()  # test data 이기 때문에, class가 없는 것을 확인!\n",
    "\n",
    "# 데이터 누락 check\n",
    "# .csv 에 있는 list와, 실제 data list의 개수가 맞는지 비교 확인\n",
    "# dataframe.colname 하면 해당 값이 나온다.\n",
    "if set(list(df_train.img_file)) == set(os.listdir(TRAIN_IMG_PATH)) :\n",
    "    print(\"Train file 누락 없음!\")\n",
    "else:\n",
    "    print(\"Train file 누락!\")\n",
    "\n",
    "if set(list(df_test.img_file)) == set(os.listdir(TEST_IMG_PATH)) :\n",
    "    print(\"Test file 누락 없음!\")\n",
    "else:\n",
    "    print(\"Test file 누락!\")\n",
    "\n",
    "# Data 개수 확인!\n",
    "# train : 9990\n",
    "# test  : 6150\n",
    "print(\"Number of Train Data : {}\".format(df_train.shape[0]))\n",
    "print(\"Number of Test  Data : {}\".format(df_test.shape[0]))\n",
    "\n",
    "# 클래스 개수 및 target vriable class 개수 확인 \n",
    "# 실제로, 매핑되지 않을 수도 있음\n",
    "# -> 196개로 동일 !\n",
    "print(\"총 클래스 개수 : {}\".format(df_class.shape[0]))\n",
    "print(\"총 클래스 개수 : {}\".format(df_train['class'].nunique()))\n",
    "\n",
    "\n",
    "# Class Distribution\n",
    "\n",
    "# seaborn library 이용.\n",
    "# 그리고자 할 data , order 를 주고싶은 경우, 해당 index 입력!(아마도..)\n",
    "plt.figure(figsize = (12, 6)) # img size setting\n",
    "sns.countplot(df_train[\"class\"], order = df_train[\"class\"].value_counts(ascending = True).index) # countplot(x=\"column_name\", data=dataframe)\n",
    "plt.title(\"Number of data per each class\")\n",
    "plt.show()\n",
    "\n",
    "# -> plot 해석\n",
    "# 대부분 class 의 개수가 고르게 분포되어 있음을 확인\n",
    "\n",
    "# class 개수의 min, max 확인\n",
    "cntEachClass = df_train[\"class\"].value_counts(ascending=False)\n",
    "print(\"최대 class 개수 : {}\".format(cntEachClass.max()))\n",
    "print(\"최소 class 개수 : {}\".format(cntEachClass.min()))\n",
    "\n",
    "cntEachClass.describe() # describe 함수를 통한 요약 정보 파악\n",
    "\n",
    "# 파이썬에서 이미지 보고 싶은 경우,\n",
    "# PIL library ->  이미지 로드하는 라이브러리라고 생각하자\n",
    "\n",
    "import PIL\n",
    "from PIL import ImageDraw\n",
    "\n",
    "tmp_imgs = df_train['img_file'][100:110] # 이미지 10개 사용\n",
    "plt.figure(figsize = (12, 20))           # 사진 size 설정\n",
    "for num, f_name in enumerate(tmp_imgs):  \n",
    "    img = PIL.Image.open(os.path.join(TRAIN_IMG_PATH, f_name)) # PIL library 의 image open 함수 이용 PATH, NAME 필요\n",
    "    plt.subplot(5, 2, num + 1) # 5행 1열중, num + 1 째 위치(?)\n",
    "    plt.title(f_name)          # Image title 설정\n",
    "    plt.imshow(img)            # show\n",
    "    plt.axis('off')            # 축은 안보이게 off\n",
    "\n",
    "# Bounding Box\n",
    "# 이미지 내부에서 특정 object를 박스로 레이블한 좌표\n",
    "# 좌측 상단, 우측 하단 좌표가 주어진다\n",
    "# 좌표는 이미지의 픽셀 좌표 \n",
    "\n",
    "# draw_rect\n",
    "# 이미지의 Bounding Box 를 그려주는 함수 \n",
    "# @param drawcontext -> 그리고자 하는 img 객체(ImageDraw.Draw(img))\n",
    "# @param pos,        -> [x1, y1, x2, y2]\n",
    "# @param outline     -> 선의 색깔\n",
    "# @param width       ->  선의 폭\n",
    "def draw_rect(drawcontext, pos, outline = None, width = 0) : #\n",
    "    (x1, y1) = (pos[0], pos[1]) # x1, y1 입력\n",
    "    (x2, y2) = (pos[2], pos[3]) # x2, y2 입력\n",
    "    points   =  (x1, y1), (x2, y1), (x2, y2), (x1, y2), (x1, y1) # 선을 4개 긋기 위한 좌표 5개. 다시 (x1, y1) 으로 회귀\n",
    "    drawcontext.line(points, fill = outline, width = width) # drawcontext.line function\n",
    "\n",
    "# make_boxing_img function\n",
    "# bounding box를 적용한 이미지 출력 함수.\n",
    "# 기존 좌표로 주어진, (x1, y1, x2, y2) 의 bounding axis가 제대로 되어 있는지? 함 확인하고자 만든 함수.\n",
    "# @param img_name -> 이미지 이름\n",
    "def make_boxing_img(img_name):\n",
    "    # img가 train, test 인지 여부에 따라 PATH, data 각각 저장\n",
    "    if img_name.split('_')[0] == \"train\" :\n",
    "          PATH = TRAIN_IMG_PATH\n",
    "          data = df_train\n",
    "    elif img_name.split('_')[0] == \"test\" :\n",
    "        \n",
    "        PATH = TEST_IMG_PATH\n",
    "        data = df_test\n",
    "    \n",
    "    # 선이 그려지지 않은 이미지 한개를 open 할 객체를 img에 저장\n",
    "    img = PIL.Image.open(os.path.join(PATH, img_name))\n",
    "    # reshape 함수는 Python을 통해 머신러닝 혹은 딥러닝 코딩을 하다보면 꼭 나오는 numpy 내장 함수입니다.\n",
    "    #  reshape(-1) 인 경우 -> 구조화 되어 있는 dataframe을 1차원 배열을 반환  \n",
    "    pos = data.loc[data[\"img_file\"] == img_name, ['bbox_x1', 'bbox_y1', 'bbox_x2', 'bbox_y2']].values.reshape(-1) # values : header를 제거하고 값만 가져오는 함수.\n",
    "    draw = ImageDraw.Draw(img)                        # 이미지를 그리고,\n",
    "    draw_rect(draw, pos, outline = 'red', width = 10) # Bounding Box를 생성\n",
    "        \n",
    "    return img\n",
    "\n",
    "f_name = \"train_00102.jpg\" # 이미지 샘플 1개 이름 저장\n",
    "plt.figure(figsize = (20, 10)) # 이미지 크기 지정 \n",
    "plt.subplot(1, 2, 1)\n",
    "\n",
    "# Original Image\n",
    "origin_img = PIL.Image.open(os.path.join(TRAIN_IMG_PATH, f_name))\n",
    "plt.title(\"Original Image - {}\".format(f_name))\n",
    "plt.imshow(origin_img)\n",
    "plt.axis('off')\n",
    "\n",
    "# Image included bounding box\n",
    "plt.subplot(1, 2, 2)\n",
    "boxing = make_boxing_img(f_name)\n",
    "plt.title(\"Boxing Image - {}\".format(f_name))\n",
    "plt.imshow(boxing)\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# 분류 모델 만들기\n",
    "# ResNet50 Pretrained Model 불러와 사용해보자\n",
    "\n",
    "# Train_test_split : Train 과 Test 를 split(?)\n",
    "from sklearn.model_selection import train_test_split # train_test_split function 호출\n",
    "df_train[\"class\"] = df_train[\"class\"].astype('str')  # class column data -> str로 변경\n",
    "\n",
    "# 이번 모델링에서 Bounding Box를 쓰지 않기때문에, 해당 컬럼은 빼고 다시 저장\n",
    "df_train = df_train[['img_file', 'class']] \n",
    "df_test  = df_test[['img_file']]\n",
    "\n",
    "its = np.arange(df_train.shape[0]) # arange -> [0:10016]\n",
    "train_idx, val_idx = train_test_split(its, train_size = 0.8, random_state=42) # 해당 idx 번호를 8:2 로 데이터 셋 분할(CV 생성)\n",
    "\n",
    "X_train = df_train.iloc[train_idx, :]\n",
    "X_val   = df_train.iloc[val_idx, :]\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(df_test.shape)\n",
    "\n",
    "# Keras Generator 사용\n",
    "\n",
    "from keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# parameter\n",
    "img_size = (224, 224) # 225, 225개의 행, 열\n",
    "nb_train_samples = len(X_train)    # 샘플 수(train data 개수) \n",
    "nb_validation_samples = len(X_val) # 샘플 수(valiadation data 개수)\n",
    "nb_test_samples = len(df_test)     # 샘플 수(test data 개수)\n",
    "\n",
    "epochs = 20     # 학습용 사진 전체를 한 번 사용했을 때 한 세대(이폭, epoch)이 지나갔다고 말함. 즉, 전체 train Dataset 학습을 총 20번 하겠다는 의미\n",
    "batch_size = 32 # batch size: 한 번에 처리하는 사진의 장 수\n",
    "\n",
    "# Define Generator config \n",
    "# 1.train_datagen\n",
    "train_datagen = ImageDataGenerator(\n",
    "    horizontal_flip = True,  # 좌우 뒤집기 -> 좌우 반전을 통해 데이터를 증가시키고, 모델 향상 시킬 수 있음\n",
    "    vertical_flip   = False, # 상하 뒤집기 -> \n",
    "    zoom_range      = 0.10,  # 실수 또는 [하한, 상한], 무작위 줌을 위한 범위\n",
    "    preprocessing_function = preprocess_input # vgg16용 preprocess_input을 사용.\n",
    ")\n",
    "\n",
    "# 2. val_datagen, test_datagen\n",
    "# train_datagen 과는 달리, 다른 parameter 값을 setting 하지 않음\n",
    "val_datagen  = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "# Make Generator\n",
    "# 해당 parameter 는 keras 책을 더 공부하고 알 수 있을듯 하다\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "\n",
    "    dataframe =  X_train,            # 실제 데이터의 img.name / class 존재하는 dataframe\n",
    "    directory = '../input/train/',   # 해당 데이터의 존재 directory\n",
    "    x_col     = 'img_file',          # x -> img_file \n",
    "    y_col     = 'class',             # y -> class\n",
    "    target_size = img_size,          # img_size -> (225, 225)\n",
    "    color_mode = 'rgb',\n",
    "    class_mode = 'categorical',      # 196개의 class -> categorical_entropy. 2진 분류시 crossentropy..\n",
    "    batch_size = batch_size,         # 32\n",
    "    seed = 42                        # 계속 동일한 값을 가져오기 위해 seed 값 지정\n",
    "    \n",
    ")\n",
    "\n",
    "# 2. validation_generator \n",
    "validation_generator = val_datagen.flow_from_dataframe(\n",
    "    \n",
    "    dataframe   = X_val,             \n",
    "    directory   = '../input/train',\n",
    "    x_col       = 'img_file',\n",
    "    y_col       = 'class',\n",
    "    target_size = img_size,\n",
    "    color_mode  = 'rgb',\n",
    "    class_mode  = 'categorical',\n",
    "    batch_size  = batch_size,\n",
    "    shuffle     = False\n",
    "    \n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    dataframe   = df_test,\n",
    "    directory   = '../input/test',\n",
    "    x_col       = 'img_file',\n",
    "    y_col       = None,\n",
    "    target_size = img_size,\n",
    "    color_mode  = 'rgb',\n",
    "    class_mode  = None,\n",
    "    batch_size  = batch_size,\n",
    "    shuffle     = False\n",
    ")\n",
    "\n",
    "\n",
    "# Pretained Model을  불러오기 위해서는 커널의 Internet 옵션이 활성화 되어 있어야 함\n",
    "resNet_model = ResNet50(\n",
    "    include_top = False,         # 최상단의 softmax 레이어를 제거\n",
    "    input_shape = (224,224,3)    # input Tensor -> 224, 224, 3\n",
    ")\n",
    "\n",
    "# ResNet50을 실제로 만들어보자\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation, Conv2D, GlobalAveragePooling2D\n",
    "\n",
    "model = Sequential()     # model 객체 생성\n",
    "model.add(resNet_model)  # resNet_model frame 추가\n",
    "model.add(GlobalAveragePooling2D()) # \n",
    "model.add(Dense(196, activation = 'softmax', kernel_initializer = 'he_normal')) # 최종 output layer. 가중치 초기화 -> he_normal 방식 이용\n",
    "\n",
    "model.summary()\n",
    "# Model Compile \n",
    "# 이제 모델을 만들었으니, 어떻게 학습할지를 정해야 함.\n",
    "# 어떤 방법으로, 어떤 속도로, 어떤 지표를 기준으로 등등 정할 수 있음\n",
    "\n",
    "from sklearn.metrics import f1_score # sklearn에 f1_score 함수 호출\n",
    "\n",
    "def micro_f1(y_true, y_pred):\n",
    "    return f1_score(y_true, y_pred, average = 'micro')\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',                       # optimizer -> adam..? , 케라스 예제에서는 rmsprop을 쓰던데..\n",
    "    loss = 'categorical_crossentropy',      # categorical_crossentropy\n",
    "    metrics = ['acc']                       # 정확도 계산..?\n",
    ")\n",
    "\n",
    "# Model Training\n",
    "# step_for_epoch를 구하기 위한 함수인듯.\n",
    "# 나머지가  0이면, 나누어 떨어진다는 뜻이므로, // .\n",
    "# 나머지가 >0이면, //에 +1\n",
    "def get_steps(num_samples, batch_size):\n",
    "    if (num_samples % batch_size) > 0:\n",
    "        return (num_samples // batch_size) + 1\n",
    "    else:\n",
    "        return num_samples // batch_size\n",
    "\n",
    "%%time\n",
    "# ModelCheckpoint -> callback함수로, 매 epoch 마다 학습된 가중치를 파일로 저장할 수 있음.\n",
    "# EarlyStopping   -> 이전 epoch 때와 비교해서 오차가 증가했다면 학습을 중단.\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "# model명을 acc, loss 명으로 해서 저장!\n",
    "# -> good idea 인듯!\n",
    "filepath = \"my_resnet_model_{val_acc:.2f}_{val_loss:.4f}.h5\"\n",
    "\n",
    "es = EarlyStopping(monitor='val_acc', # 관찰하고자 하는 항목\n",
    "                   min_delta =0, # 개선되고 있다고 판단하기 위한 최소 변화량\n",
    "                   patience = 3, # 개선이 없는 에포크를 얼마나 기다려 줄 것인 가를 지정\n",
    "                   verbose = 1,  # 얼마나 자세하게 정보를 표시할 것인가를 지정합니다. (0, 1, 2)\n",
    "                   mode = 'auto' # 관찰 항목에 대해 개선이 없다고 판단하기 위한 기준을 지정\n",
    "                                 # auto : 관찰하는 이름에 따라 자동으로 지정\n",
    "                                 # min  : 관찰하고 있는 항목이 감소되는 것을 멈출 때 종료\n",
    "                                 # max  : 관찰하고 있는 항목이 증가되는 것을 멈출 때 종료\n",
    "                  )\n",
    "    \n",
    "# model fit generator에 callback param에 list형태로 들어가야 하므로, list 로 저장\n",
    "callbackList = [es] \n",
    "\n",
    "# 모델 학습.\n",
    "# 꽤 오랜시간이 걸리므로, 자기 전에 돌리고 자자^^ \n",
    "history = model.fit_generator(\n",
    "\n",
    "    train_generator,\n",
    "    steps_per_epoch  = get_steps(nb_train_samples, batch_size),\n",
    "    epochs           = epochs,\n",
    "    validation_data  = validation_generator,\n",
    "    validation_steps = get_steps(nb_validation_samples, batch_size), \n",
    "    callbacks        = callbackList\n",
    ")\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "# Training History Visualization\n",
    "# 학습된 결과를 plot으로 그려볼 수 있음.\n",
    "# \n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Predict & Make submission\n",
    "# Model predict\n",
    "%%time\n",
    "test_generator.reset()\n",
    "prediction = model.predict_gerator(\n",
    "\n",
    "    generator = test_generator,\n",
    "    steps     = get_steps(nb_test_samples, batch_size),\n",
    "    verbose   = 1 \n",
    ")\n",
    "\n",
    "# 중요!\n",
    "# 케라스 제너레이터를 사용하는 경우에는 타겟(클래스)의 카테고리컬 매핑이\n",
    "# 제너레이터 임의로 결정.\n",
    "# 따라서 제너레이터가 가지고 있는 class index 딕셔너리 불러와 새롭게 매핑해주어야 함.\n",
    "\n",
    "predicted_class_indices = np.argmax(prediction, axis = 1)\n",
    "\n",
    "# Generator class dictionary mapping\n",
    "labels      = (train_generator.class_indices)\n",
    "labels      = dict((v,k) for k,v in labels.items())\n",
    "predictions = [labels[k] for k in predicted_class_indices]\n",
    "\n",
    "submission          = pd.read_csv(os.path.join(DATA_PATH, 'sample_submission.csv'))\n",
    "submission[\"class\"] = predictions\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "submission.head()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
